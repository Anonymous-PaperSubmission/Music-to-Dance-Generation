{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from moviepy.editor import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "import matplotlib.animation as animation\n",
    "import scipy.io as sio\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, sr=48000):\n",
    "    y, _ = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "    # Set the hop length for 25 fps\n",
    "    hop_length = sr // 25\n",
    "\n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "    # Beat track on the percussive signal\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "\n",
    "    # Compute MFCC features from the raw signal\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=16)\n",
    "\n",
    "    # Compute the first-order differences of the MFCC features\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "\n",
    "    # Stack MFCC and MFCC delta features and aggregate between beat events using mean\n",
    "    beat_mfcc_features = librosa.util.sync(np.vstack([mfcc, mfcc_delta]), beat_frames)\n",
    "\n",
    "    # Compute chroma features from the harmonic signal\n",
    "    chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr, hop_length=hop_length)\n",
    "\n",
    "    # Aggregate chroma features between beat events using median\n",
    "    beat_chroma = librosa.util.sync(chromagram, beat_frames, aggregate=np.median)\n",
    "\n",
    "    # Finally, stack all beat-synchronous features together\n",
    "    beat_features = np.vstack([beat_chroma, beat_mfcc_features])\n",
    "    return beat_features, beat_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"Processed/DANCE_C_1.mp3\"\n",
    "beat_features, beat_frames = extract_features(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 48000\n",
    "audio_path = \"Processed/gBR_sBM_c01_d04_mBR0_ch01.mp4\"\n",
    "y, sr = librosa.load(audio_path, sr, offset=1.0, duration=3.0)\n",
    "\n",
    "# Set the hop length for 25 fps\n",
    "hop_length = sr // 25\n",
    "\n",
    "# Separate harmonics and percussives into two waveforms\n",
    "y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "#display waveform\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(y_harmonic, sr=sr, color='b')\n",
    "ax = plt.gca()\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y_harmonic, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = librosa.time_to_samples(15, sr=sr)\n",
    "intro = y[:first]\n",
    "intro_harm = librosa.effects.harmonic(intro)\n",
    "intro_chroma = librosa.feature.chroma_cqt(intro_harm, sr=sr, hop_length=hop_length)\n",
    "librosa.display.specshow(intro_chroma, sr=sr, hop_length=hop_length, y_axis='chroma', x_axis='time')\n",
    "plt.title('Chroma Spectrogram')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr=48000\n",
    "\n",
    "y, _ = librosa.load(audio_path, sr=sr, offset=15.0, duration=12.0)\n",
    "\n",
    "# Set the hop length for 25 fps\n",
    "hop_length = sr // 25\n",
    "\n",
    "# Separate harmonics and percussives into two waveforms\n",
    "y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "# Beat track on the percussive signal\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "\n",
    "# Compute MFCC features from the raw signal\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr, hop_length=hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for music in glob.glob('Music/*.mp3'):\n",
    "    audio_path = music[6:-4]\n",
    "    sr = 48000\n",
    "\n",
    "    y, sr = librosa.load(music, sr)\n",
    "\n",
    "    # Set the hop length for 25 fps\n",
    "    hop_length = sr // 25\n",
    "\n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "    h = max(abs(y_harmonic))\n",
    "    #display waveform\n",
    "    %matplotlib qt\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    librosa.display.waveplot(y_harmonic, sr=sr, color='b')\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    patch = matplotlib.patches.Rectangle((0, -h), width=0, height=2*h, fc=[1,1,1,0.5])\n",
    "    ax.add_patch(patch)\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_width(i/25)\n",
    "        return patch,\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate,\n",
    "                                   frames=250,\n",
    "                                   interval=40,\n",
    "                                   blit=True)\n",
    "    FFwriter = animation.FFMpegWriter(fps=25)\n",
    "    anim.save('Music/{}.mp4'.format(audio_path), writer=FFwriter, dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ['Waltz_Gen', 'ChaCha_Gen']:\n",
    "    music = f'Test/Video/{file}.mp3'\n",
    "\n",
    "    sr = 48000\n",
    "\n",
    "    y, sr = librosa.load(music, sr, offset=0.0, duration=12.0)\n",
    "\n",
    "    # Set the hop length for 25 fps\n",
    "    hop_length = sr // 25\n",
    "\n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "\n",
    "    h = max(abs(y_harmonic))\n",
    "    #display waveform\n",
    "    %matplotlib qt\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    librosa.display.waveplot(y_harmonic, sr=sr, color=[0.9,0.7,0.7])\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    patch = matplotlib.patches.Rectangle((0, -h), width=0, height=2*h, fc=[1,1,1,0.5])\n",
    "    ax.add_patch(patch)\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_width(i/25)\n",
    "        return patch,\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate,\n",
    "                                   frames=300,\n",
    "                                   interval=40,\n",
    "                                   blit=True)\n",
    "    FFwriter = animation.FFMpegWriter(fps=25)\n",
    "    anim.save(f'Test/Video/{file}.mp4', writer=FFwriter, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('ffmpeg -y -i ChaCha_Gen.wav -ss 00:00:02.5 -t 00:00:12.0 -vn -ar 44100 -ac 2 -b:a 192k Test/Video/ChaCha_Gen.mp3')\n",
    "os.system('ffmpeg -y -i ChaCha.mp3 -ss 00:00:02.5 -t 00:00:12.0 -vn -ar 44100 -ac 2 -b:a 192k Test/Video/ChaCha.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('ffmpeg -y -i Waltz_Gen.wav -ss 00:00:03 -t 00:00:12.0 -vn -ar 44100 -ac 2 -b:a 192k Test/Video/Waltz_Gen.mp3')\n",
    "os.system('ffmpeg -y -i Waltz.mp3 -ss 00:00:03 -t 00:00:12.0 -vn -ar 44100 -ac 2 -b:a 192k Test/Video/Waltz.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
